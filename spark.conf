[SPARK_APP_CONFIGS]
spark.app.name = PrimeNumbers
spark.master = spark://10.88.54.39:7077
# spark.master = local[*]
spark.submit.deployMode = cluster
# spark.sql.shuffle.partitions = 2
 
# spark.shuffle.service.enabled = false
spark.dynamicAllocation.enabled = true
 
spark.driver.memory = 5g
spark.executor.memory = 5g
spark.executor.cores = 8
# spark.executor.instances =   
 
spark.driver.host = 10.88.54.39
spark.blockManager.port = 10025
spark.driver.blockManager.port = 10026
spark.driver.port = 10027
# spark.jars=file://${SPARK_JARS_PATH}/aws-java-sdk-bundle-1.11.1026.jar,file://${SPARK_JARS_PATH}/hadoop-aws-3.3.2.jar
# spark.jars=file:///home/phinguyen/spark-3.5.4-bin-hadoop3/jars/aws-java-sdk-bundle-1.11.1026.jar,file:///home/phinguyen/spark-3.5.4-bin-hadoop3/jars/hadoop-aws-3.3.2.jar,file:///home/kha/spark/spark-3.5.3-bin-hadoop3/jars/hadoop-aws-3.3.2.jar,file:///home/kha/spark/spark-3.5.3-bin-hadoop3/ws-java-sdk-bundle-1.11.1026.jar
# spark-submit ex_1.py --conf spark.jars=file:///home/phinguyen/spark-3.5.4-bin-hadoop3/jars/aws-java-sdk-bundle-1.11.1026.jar,file:///home/phinguyen/spark-3.5.4-bin-hadoop3/jars/hadoop-aws-3.3.2.jar,file:///home/kha/spark/spark-3.5.3-bin-hadoop3/jars/hadoop-aws-3.3.2.jar,file:///home/kha/spark/spark-3.5.3-bin-hadoop3/ws-java-sdk-bundle-1.11.1026.jar

# [EX_2]
# spark.app.name = Exercice_2
# spark.master = local[*]

